{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import detectron2\n",
    "from pathlib import Path\n",
    "import random, cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, DatasetMapper, build\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.engine import BestCheckpointer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "from detectron2 import solver\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/17 00:35:37 d2.data.datasets.coco]: \u001b[0mLoading ../input/sartorius-cell-instance-segmentation-coco/annotations_train.json takes 1.46 seconds.\n",
      "\u001b[32m[12/17 00:35:37 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_train.json\n"
     ]
    }
   ],
   "source": [
    "dataDir=Path('../input/sartorius-cell-instance-segmentation/')\n",
    "cfg = get_cfg()\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "register_coco_instances('sartorius_train',{}, '../input/sartorius-cell-instance-segmentation-coco/annotations_train.json', dataDir)\n",
    "register_coco_instances('sartorius_val',{},'../input/sartorius-cell-instance-segmentation-coco/annotations_val.json', dataDir)\n",
    "metadata = MetadataCatalog.get('sartorius_train')\n",
    "train_ds = DatasetCatalog.get('sartorius_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize, do not run in server\n",
    "# d = train_ds[42]\n",
    "# img = cv2.imread(d[\"file_name\"])\n",
    "# visualizer = Visualizer(img[:, :, ::-1], metadata=metadata)\n",
    "# out = visualizer.draw_dataset_dict(d)\n",
    "# plt.figure(figsize = (20,15))\n",
    "# plt.imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://www.kaggle.com/theoviel/competition-metric-map-iou\n",
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n",
    "    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ):\n",
    "    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n",
    "    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n",
    "    enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, ious)\n",
    "        p = tp / (tp + fp + fn)\n",
    "        prec.append(p)\n",
    "    return np.mean(prec)\n",
    "\n",
    "class MAPIOUEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for inp, out in zip(inputs, outputs):\n",
    "            if len(out['instances']) == 0:\n",
    "                self.scores.append(0)    \n",
    "            else:\n",
    "                targ = self.annotations_cache[inp['image_id']]\n",
    "                self.scores.append(score(out, targ))\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {\"MaP IoU\": np.mean(self.scores)}\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    \n",
    "    # @classmethod\n",
    "    # def build_train_loader(cls, cfg):\n",
    "    #     return build_detection_train_loader(cfg, mapper=DatasetMapper(cfg, is_train=True, augmentations=[\n",
    "    #             T.ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'),               \n",
    "\t# \t        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "    #             T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "    #         ]))\n",
    "    \n",
    "    # @classmethod\n",
    "    # def build_optimizer(cfg, model):\n",
    "    \n",
    "        \n",
    "    #     return torch.optim.Adadelta(\n",
    "    #         model.paramaters(),\n",
    "    #         lr=cfg.SOLVER.BASE_LR,\n",
    "    #     )\n",
    "\n",
    "    # @classmethod\n",
    "    # def build_train_loader(cls, cfg):\n",
    "    #     return build.build_detection_train_loader(cfg, mapper=DatasetMapper(cfg, is_train=True, augmentations=[\n",
    "    #             T.RandomBrightness(0.9, 1.1),\n",
    "    #             T.RandomContrast(0.9, 1.1),\n",
    "    #             T.RandomSaturation(0.9, 1.1),\n",
    "    #             T.RandomLighting(0.9),\n",
    "    #             T.ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'),               \n",
    "\t# \t        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "    #             T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "    #         ]))\n",
    "            \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluator(dataset_name)\n",
    "\n",
    "    def build_hooks(self):\n",
    "\n",
    "        # copy of cfg\n",
    "        cfg = self.cfg.clone()\n",
    "\n",
    "        # build the original model hooks\n",
    "        hooks = super().build_hooks()\n",
    "\n",
    "        # add the best checkpointer hook\n",
    "        hooks.insert(-1, BestCheckpointer(cfg.TEST.EVAL_PERIOD, \n",
    "                                         DetectionCheckpointer(self.model, cfg.OUTPUT_DIR),\n",
    "                                         \"MaP IoU\",\n",
    "                                         \"max\",\n",
    "                                         ))\n",
    "        return hooks\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/17 00:35:46 d2.data.datasets.coco]: \u001b[0mLoading ../input/sartorius-cell-instance-segmentation-coco/annotations_train.json takes 1.18 seconds.\n",
      "\u001b[32m[12/17 00:35:46 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_train.json\n",
      "\u001b[32m[12/17 00:35:52 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[12/17 00:35:53 d2.data.datasets.coco]: \u001b[0mLoading ../input/sartorius-cell-instance-segmentation-coco/annotations_train.json takes 1.38 seconds.\n",
      "\u001b[32m[12/17 00:35:53 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_train.json\n",
      "\u001b[32m[12/17 00:35:54 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[12/17 00:35:54 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[12/17 00:35:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/17 00:35:54 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/17 00:35:54 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 00:35:54 d2.data.common]: \u001b[0mSerialized dataset takes 6.73 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = './model_best.pth'  # Let training initialize from pretrained model\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 10000    \n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\" \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH  # Once per epoch\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/17 00:35:57 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaoyiyuan/miniconda3/envs/NMDA_gaoyy/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/home/gaoyiyuan/miniconda3/envs/NMDA_gaoyy/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/17 00:36:30 d2.utils.events]: \u001b[0m eta: 2:01:27  iter: 19  total_loss: 3.042  loss_cls: 1.427  loss_box_reg: 0.2707  loss_mask: 0.695  loss_rpn_cls: 0.3436  loss_rpn_loc: 0.2637  time: 1.5460  data_time: 1.2835  lr: 1.9516e-05  max_mem: 4664M\n",
      "\u001b[32m[12/17 00:36:55 d2.utils.events]: \u001b[0m eta: 1:44:54  iter: 39  total_loss: 2.921  loss_cls: 1.28  loss_box_reg: 0.4274  loss_mask: 0.6836  loss_rpn_cls: 0.2449  loss_rpn_loc: 0.2322  time: 1.3895  data_time: 0.9491  lr: 3.9007e-05  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:37:21 d2.utils.events]: \u001b[0m eta: 1:39:50  iter: 59  total_loss: 2.422  loss_cls: 0.9201  loss_box_reg: 0.2959  loss_mask: 0.6552  loss_rpn_cls: 0.2479  loss_rpn_loc: 0.2685  time: 1.3576  data_time: 0.9752  lr: 5.8497e-05  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:37:43 d2.utils.events]: \u001b[0m eta: 1:31:23  iter: 79  total_loss: 2.103  loss_cls: 0.6825  loss_box_reg: 0.341  loss_mask: 0.6067  loss_rpn_cls: 0.2125  loss_rpn_loc: 0.2432  time: 1.2932  data_time: 0.7623  lr: 7.7988e-05  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:38:14 d2.utils.events]: \u001b[0m eta: 1:34:42  iter: 99  total_loss: 2.168  loss_cls: 0.6787  loss_box_reg: 0.4493  loss_mask: 0.5793  loss_rpn_cls: 0.1967  loss_rpn_loc: 0.253  time: 1.3448  data_time: 1.1563  lr: 9.7478e-05  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:38:41 d2.utils.events]: \u001b[0m eta: 1:36:22  iter: 119  total_loss: 2.13  loss_cls: 0.698  loss_box_reg: 0.5039  loss_mask: 0.5322  loss_rpn_cls: 0.1597  loss_rpn_loc: 0.2075  time: 1.3439  data_time: 0.8795  lr: 0.00011697  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:39:05 d2.utils.events]: \u001b[0m eta: 1:43:22  iter: 139  total_loss: 2.18  loss_cls: 0.679  loss_box_reg: 0.5901  loss_mask: 0.49  loss_rpn_cls: 0.175  loss_rpn_loc: 0.2243  time: 1.3247  data_time: 0.6289  lr: 0.00013646  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:39:34 d2.utils.events]: \u001b[0m eta: 1:50:32  iter: 159  total_loss: 1.927  loss_cls: 0.5739  loss_box_reg: 0.6456  loss_mask: 0.4407  loss_rpn_cls: 0.1378  loss_rpn_loc: 0.2017  time: 1.3422  data_time: 0.6775  lr: 0.00015595  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:40:07 d2.utils.events]: \u001b[0m eta: 1:56:22  iter: 179  total_loss: 1.966  loss_cls: 0.6034  loss_box_reg: 0.5914  loss_mask: 0.4312  loss_rpn_cls: 0.1761  loss_rpn_loc: 0.2419  time: 1.3748  data_time: 0.9894  lr: 0.00017544  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:40:38 d2.utils.events]: \u001b[0m eta: 2:13:18  iter: 199  total_loss: 1.906  loss_cls: 0.5129  loss_box_reg: 0.6694  loss_mask: 0.3848  loss_rpn_cls: 0.1199  loss_rpn_loc: 0.2277  time: 1.3922  data_time: 0.3688  lr: 0.00019493  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:41:15 d2.utils.events]: \u001b[0m eta: 2:19:40  iter: 219  total_loss: 1.849  loss_cls: 0.4722  loss_box_reg: 0.5693  loss_mask: 0.3609  loss_rpn_cls: 0.1476  loss_rpn_loc: 0.2299  time: 1.4339  data_time: 1.0731  lr: 0.00021442  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:41:42 d2.utils.events]: \u001b[0m eta: 2:36:33  iter: 239  total_loss: 1.659  loss_cls: 0.4314  loss_box_reg: 0.6107  loss_mask: 0.3409  loss_rpn_cls: 0.116  loss_rpn_loc: 0.2307  time: 1.4265  data_time: 0.2034  lr: 0.00023391  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:41:45 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 00:41:45 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[12/17 00:41:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/17 00:41:45 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 00:41:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.73 MiB\n",
      "\u001b[32m[12/17 00:41:46 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 00:41:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/17 00:41:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0014 s/iter. Inference: 0.2791 s/iter. Eval: 0.0143 s/iter. Total: 0.2948 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/17 00:41:54 d2.evaluation.evaluator]: \u001b[0mInference done 29/121. Dataloading: 0.0016 s/iter. Inference: 0.2738 s/iter. Eval: 0.0169 s/iter. Total: 0.2925 s/iter. ETA=0:00:26\n",
      "\u001b[32m[12/17 00:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0016 s/iter. Inference: 0.2688 s/iter. Eval: 0.0198 s/iter. Total: 0.2905 s/iter. ETA=0:00:21\n",
      "\u001b[32m[12/17 00:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 65/121. Dataloading: 0.0016 s/iter. Inference: 0.2677 s/iter. Eval: 0.0218 s/iter. Total: 0.2913 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/17 00:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 85/121. Dataloading: 0.0016 s/iter. Inference: 0.2592 s/iter. Eval: 0.0215 s/iter. Total: 0.2825 s/iter. ETA=0:00:10\n",
      "\u001b[32m[12/17 00:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0017 s/iter. Inference: 0.2293 s/iter. Eval: 0.0226 s/iter. Total: 0.2538 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/17 00:42:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.081436 (0.250702 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 00:42:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:26 (0.226086 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 00:42:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/17 00:42:16 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.1613363699350985\n",
      "\u001b[32m[12/17 00:42:17 d2.engine.hooks]: \u001b[0mSaved first model at 0.16134 @ 241 steps\n",
      "\u001b[32m[12/17 00:42:43 d2.utils.events]: \u001b[0m eta: 2:54:48  iter: 259  total_loss: 1.728  loss_cls: 0.4222  loss_box_reg: 0.6398  loss_mask: 0.3327  loss_rpn_cls: 0.08615  loss_rpn_loc: 0.2205  time: 1.4286  data_time: 0.1273  lr: 0.0002534  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:43:19 d2.utils.events]: \u001b[0m eta: 3:08:20  iter: 279  total_loss: 1.625  loss_cls: 0.3515  loss_box_reg: 0.6276  loss_mask: 0.3299  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.2158  time: 1.4560  data_time: 0.7389  lr: 0.00027289  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:43:55 d2.utils.events]: \u001b[0m eta: 3:26:14  iter: 299  total_loss: 1.63  loss_cls: 0.3926  loss_box_reg: 0.6211  loss_mask: 0.305  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.2022  time: 1.4774  data_time: 0.2517  lr: 0.00029238  max_mem: 5716M\n",
      "\u001b[32m[12/17 00:44:25 d2.utils.events]: \u001b[0m eta: 3:24:39  iter: 319  total_loss: 1.756  loss_cls: 0.4477  loss_box_reg: 0.617  loss_mask: 0.3308  loss_rpn_cls: 0.1355  loss_rpn_loc: 0.2303  time: 1.4794  data_time: 0.4377  lr: 0.00031187  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:44:58 d2.utils.events]: \u001b[0m eta: 3:23:42  iter: 339  total_loss: 1.615  loss_cls: 0.3898  loss_box_reg: 0.5817  loss_mask: 0.2985  loss_rpn_cls: 0.09895  loss_rpn_loc: 0.185  time: 1.4892  data_time: 0.8607  lr: 0.00033137  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:45:29 d2.utils.events]: \u001b[0m eta: 3:23:49  iter: 359  total_loss: 1.623  loss_cls: 0.3681  loss_box_reg: 0.5742  loss_mask: 0.3112  loss_rpn_cls: 0.1172  loss_rpn_loc: 0.2393  time: 1.4925  data_time: 0.8259  lr: 0.00035086  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:45:57 d2.utils.events]: \u001b[0m eta: 3:26:17  iter: 379  total_loss: 1.639  loss_cls: 0.3839  loss_box_reg: 0.5869  loss_mask: 0.3145  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.2114  time: 1.4884  data_time: 0.2013  lr: 0.00037035  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:46:31 d2.utils.events]: \u001b[0m eta: 3:24:07  iter: 399  total_loss: 1.577  loss_cls: 0.3391  loss_box_reg: 0.5622  loss_mask: 0.3118  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.2258  time: 1.4975  data_time: 0.7710  lr: 0.00038984  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:47:06 d2.utils.events]: \u001b[0m eta: 3:25:26  iter: 419  total_loss: 1.677  loss_cls: 0.4206  loss_box_reg: 0.578  loss_mask: 0.3099  loss_rpn_cls: 0.1163  loss_rpn_loc: 0.2336  time: 1.5113  data_time: 1.2451  lr: 0.00040933  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:47:30 d2.utils.events]: \u001b[0m eta: 3:22:07  iter: 439  total_loss: 1.544  loss_cls: 0.3805  loss_box_reg: 0.5529  loss_mask: 0.3083  loss_rpn_cls: 0.1123  loss_rpn_loc: 0.22  time: 1.4954  data_time: 0.4938  lr: 0.00042882  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:47:59 d2.utils.events]: \u001b[0m eta: 3:20:39  iter: 459  total_loss: 1.547  loss_cls: 0.3374  loss_box_reg: 0.5328  loss_mask: 0.312  loss_rpn_cls: 0.112  loss_rpn_loc: 0.2054  time: 1.4950  data_time: 0.9514  lr: 0.00044831  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:48:26 d2.utils.events]: \u001b[0m eta: 3:20:14  iter: 479  total_loss: 1.585  loss_cls: 0.3819  loss_box_reg: 0.5847  loss_mask: 0.3155  loss_rpn_cls: 0.09637  loss_rpn_loc: 0.2146  time: 1.4886  data_time: 0.5865  lr: 0.0004678  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:48:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 00:48:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/17 00:48:31 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 00:48:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.73 MiB\n",
      "\u001b[32m[12/17 00:48:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 00:48:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/17 00:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0016 s/iter. Inference: 0.0929 s/iter. Eval: 0.0333 s/iter. Total: 0.1278 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/17 00:48:38 d2.evaluation.evaluator]: \u001b[0mInference done 48/121. Dataloading: 0.0048 s/iter. Inference: 0.0891 s/iter. Eval: 0.0426 s/iter. Total: 0.1366 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/17 00:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0036 s/iter. Inference: 0.1068 s/iter. Eval: 0.0431 s/iter. Total: 0.1537 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/17 00:48:49 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0032 s/iter. Inference: 0.1262 s/iter. Eval: 0.0422 s/iter. Total: 0.1717 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/17 00:48:54 d2.evaluation.evaluator]: \u001b[0mInference done 121/121. Dataloading: 0.0029 s/iter. Inference: 0.1419 s/iter. Eval: 0.0393 s/iter. Total: 0.1843 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/17 00:48:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.474575 (0.185126 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 00:48:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.141869 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 00:48:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/17 00:48:54 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.23120764547521344\n",
      "\u001b[32m[12/17 00:48:56 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is0.23121, better than last best score 0.16134 @ iteration 241.\n",
      "\u001b[32m[12/17 00:49:16 d2.utils.events]: \u001b[0m eta: 3:19:12  iter: 499  total_loss: 1.583  loss_cls: 0.3521  loss_box_reg: 0.5657  loss_mask: 0.3098  loss_rpn_cls: 0.1198  loss_rpn_loc: 0.2291  time: 1.4767  data_time: 0.6283  lr: 0.00048729  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:49:54 d2.utils.events]: \u001b[0m eta: 3:18:12  iter: 519  total_loss: 1.616  loss_cls: 0.4003  loss_box_reg: 0.5477  loss_mask: 0.3137  loss_rpn_cls: 0.119  loss_rpn_loc: 0.2161  time: 1.4917  data_time: 1.3734  lr: 0.00050678  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:50:24 d2.utils.events]: \u001b[0m eta: 3:18:22  iter: 539  total_loss: 1.562  loss_cls: 0.3705  loss_box_reg: 0.5649  loss_mask: 0.3116  loss_rpn_cls: 0.09469  loss_rpn_loc: 0.2036  time: 1.4920  data_time: 0.6372  lr: 0.00052627  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:50:55 d2.utils.events]: \u001b[0m eta: 3:17:22  iter: 559  total_loss: 1.554  loss_cls: 0.3622  loss_box_reg: 0.5308  loss_mask: 0.304  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.2197  time: 1.4956  data_time: 0.8305  lr: 0.00054576  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:51:25 d2.utils.events]: \u001b[0m eta: 3:11:53  iter: 579  total_loss: 1.489  loss_cls: 0.3561  loss_box_reg: 0.5606  loss_mask: 0.2964  loss_rpn_cls: 0.08473  loss_rpn_loc: 0.2004  time: 1.4943  data_time: 0.8482  lr: 0.00056525  max_mem: 6034M\n",
      "\u001b[32m[12/17 00:52:03 d2.utils.events]: \u001b[0m eta: 3:14:15  iter: 599  total_loss: 1.498  loss_cls: 0.3499  loss_box_reg: 0.5446  loss_mask: 0.3058  loss_rpn_cls: 0.08136  loss_rpn_loc: 0.2042  time: 1.5081  data_time: 1.0823  lr: 0.00058474  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:52:38 d2.utils.events]: \u001b[0m eta: 3:11:04  iter: 619  total_loss: 1.6  loss_cls: 0.3667  loss_box_reg: 0.5505  loss_mask: 0.3083  loss_rpn_cls: 0.1066  loss_rpn_loc: 0.2174  time: 1.5155  data_time: 1.0517  lr: 0.00060423  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:53:09 d2.utils.events]: \u001b[0m eta: 3:08:03  iter: 639  total_loss: 1.6  loss_cls: 0.3451  loss_box_reg: 0.5356  loss_mask: 0.3203  loss_rpn_cls: 0.1249  loss_rpn_loc: 0.2194  time: 1.5174  data_time: 0.6370  lr: 0.00062372  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:53:43 d2.utils.events]: \u001b[0m eta: 3:07:39  iter: 659  total_loss: 1.532  loss_cls: 0.3647  loss_box_reg: 0.5402  loss_mask: 0.3098  loss_rpn_cls: 0.1265  loss_rpn_loc: 0.2147  time: 1.5233  data_time: 0.6515  lr: 0.00064321  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:54:18 d2.utils.events]: \u001b[0m eta: 3:06:25  iter: 679  total_loss: 1.563  loss_cls: 0.363  loss_box_reg: 0.5553  loss_mask: 0.3046  loss_rpn_cls: 0.08552  loss_rpn_loc: 0.2113  time: 1.5290  data_time: 0.7425  lr: 0.0006627  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:54:49 d2.utils.events]: \u001b[0m eta: 3:08:53  iter: 699  total_loss: 1.442  loss_cls: 0.3236  loss_box_reg: 0.5326  loss_mask: 0.299  loss_rpn_cls: 0.08138  loss_rpn_loc: 0.1921  time: 1.5295  data_time: 0.3423  lr: 0.0006822  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:55:26 d2.utils.events]: \u001b[0m eta: 3:15:11  iter: 719  total_loss: 1.582  loss_cls: 0.392  loss_box_reg: 0.5412  loss_mask: 0.313  loss_rpn_cls: 0.1179  loss_rpn_loc: 0.2147  time: 1.5389  data_time: 0.3033  lr: 0.00070169  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:55:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 00:55:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/17 00:55:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 00:55:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.73 MiB\n",
      "\u001b[32m[12/17 00:55:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 00:55:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/17 00:55:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0013 s/iter. Inference: 0.2887 s/iter. Eval: 0.0186 s/iter. Total: 0.3087 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/17 00:55:46 d2.evaluation.evaluator]: \u001b[0mInference done 27/121. Dataloading: 0.0015 s/iter. Inference: 0.2926 s/iter. Eval: 0.0196 s/iter. Total: 0.3139 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/17 00:55:51 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0017 s/iter. Inference: 0.2860 s/iter. Eval: 0.0222 s/iter. Total: 0.3100 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/17 00:55:56 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0017 s/iter. Inference: 0.2848 s/iter. Eval: 0.0237 s/iter. Total: 0.3104 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/17 00:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0017 s/iter. Inference: 0.2828 s/iter. Eval: 0.0233 s/iter. Total: 0.3079 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/17 00:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0017 s/iter. Inference: 0.2833 s/iter. Eval: 0.0224 s/iter. Total: 0.3075 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/17 00:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0017 s/iter. Inference: 0.2834 s/iter. Eval: 0.0215 s/iter. Total: 0.3068 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/17 00:56:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.692430 (0.307693 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 00:56:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.283974 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 00:56:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/17 00:56:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.20966510747021608\n",
      "\u001b[32m[12/17 00:56:15 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.20967, not better than best score 0.23121 @ iteration 483.\n",
      "\u001b[32m[12/17 00:56:41 d2.utils.events]: \u001b[0m eta: 3:17:47  iter: 739  total_loss: 1.44  loss_cls: 0.3227  loss_box_reg: 0.5323  loss_mask: 0.2892  loss_rpn_cls: 0.09148  loss_rpn_loc: 0.2092  time: 1.5459  data_time: 0.2817  lr: 0.00072118  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:57:12 d2.utils.events]: \u001b[0m eta: 3:21:09  iter: 759  total_loss: 1.502  loss_cls: 0.3467  loss_box_reg: 0.5429  loss_mask: 0.2961  loss_rpn_cls: 0.08111  loss_rpn_loc: 0.2142  time: 1.5455  data_time: 0.3091  lr: 0.00074067  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:57:45 d2.utils.events]: \u001b[0m eta: 3:23:17  iter: 779  total_loss: 1.528  loss_cls: 0.368  loss_box_reg: 0.5267  loss_mask: 0.3189  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2144  time: 1.5485  data_time: 0.4028  lr: 0.00076016  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:58:20 d2.utils.events]: \u001b[0m eta: 3:24:48  iter: 799  total_loss: 1.473  loss_cls: 0.353  loss_box_reg: 0.5319  loss_mask: 0.2921  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.2106  time: 1.5539  data_time: 0.3313  lr: 0.00077965  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:58:51 d2.utils.events]: \u001b[0m eta: 3:24:21  iter: 819  total_loss: 1.632  loss_cls: 0.3853  loss_box_reg: 0.5679  loss_mask: 0.3105  loss_rpn_cls: 0.09589  loss_rpn_loc: 0.235  time: 1.5533  data_time: 0.7752  lr: 0.00079914  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:59:20 d2.utils.events]: \u001b[0m eta: 3:22:54  iter: 839  total_loss: 1.564  loss_cls: 0.3898  loss_box_reg: 0.5602  loss_mask: 0.2962  loss_rpn_cls: 0.07681  loss_rpn_loc: 0.2076  time: 1.5516  data_time: 0.7405  lr: 0.00081863  max_mem: 6101M\n",
      "\u001b[32m[12/17 00:59:53 d2.utils.events]: \u001b[0m eta: 3:23:05  iter: 859  total_loss: 1.485  loss_cls: 0.3251  loss_box_reg: 0.5205  loss_mask: 0.2955  loss_rpn_cls: 0.07866  loss_rpn_loc: 0.2142  time: 1.5534  data_time: 0.6166  lr: 0.00083812  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:00:27 d2.utils.events]: \u001b[0m eta: 3:23:01  iter: 879  total_loss: 1.526  loss_cls: 0.3169  loss_box_reg: 0.5442  loss_mask: 0.3193  loss_rpn_cls: 0.09459  loss_rpn_loc: 0.2149  time: 1.5572  data_time: 0.9146  lr: 0.00085761  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:00:55 d2.utils.events]: \u001b[0m eta: 3:22:51  iter: 899  total_loss: 1.534  loss_cls: 0.3788  loss_box_reg: 0.5175  loss_mask: 0.3057  loss_rpn_cls: 0.0994  loss_rpn_loc: 0.2171  time: 1.5528  data_time: 0.3494  lr: 0.0008771  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:01:26 d2.utils.events]: \u001b[0m eta: 3:22:07  iter: 919  total_loss: 1.577  loss_cls: 0.3943  loss_box_reg: 0.5348  loss_mask: 0.3194  loss_rpn_cls: 0.0758  loss_rpn_loc: 0.2298  time: 1.5533  data_time: 0.7381  lr: 0.00089659  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:02:01 d2.utils.events]: \u001b[0m eta: 3:20:41  iter: 939  total_loss: 1.541  loss_cls: 0.3744  loss_box_reg: 0.5421  loss_mask: 0.2981  loss_rpn_cls: 0.1155  loss_rpn_loc: 0.2217  time: 1.5575  data_time: 0.8400  lr: 0.00091608  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:02:31 d2.utils.events]: \u001b[0m eta: 3:19:21  iter: 959  total_loss: 1.459  loss_cls: 0.3286  loss_box_reg: 0.5474  loss_mask: 0.3043  loss_rpn_cls: 0.08813  loss_rpn_loc: 0.2092  time: 1.5561  data_time: 0.5398  lr: 0.00093557  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:02:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:02:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/17 01:02:52 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 01:02:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.73 MiB\n",
      "\u001b[32m[12/17 01:02:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:02:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/17 01:02:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0015 s/iter. Inference: 0.1119 s/iter. Eval: 0.0292 s/iter. Total: 0.1426 s/iter. ETA=0:00:15\n",
      "\u001b[32m[12/17 01:03:00 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0018 s/iter. Inference: 0.1033 s/iter. Eval: 0.0458 s/iter. Total: 0.1511 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/17 01:03:05 d2.evaluation.evaluator]: \u001b[0mInference done 78/121. Dataloading: 0.0019 s/iter. Inference: 0.1042 s/iter. Eval: 0.0486 s/iter. Total: 0.1548 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/17 01:03:10 d2.evaluation.evaluator]: \u001b[0mInference done 96/121. Dataloading: 0.0019 s/iter. Inference: 0.1342 s/iter. Eval: 0.0465 s/iter. Total: 0.1828 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/17 01:03:15 d2.evaluation.evaluator]: \u001b[0mInference done 114/121. Dataloading: 0.0018 s/iter. Inference: 0.1558 s/iter. Eval: 0.0433 s/iter. Total: 0.2012 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/17 01:03:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:24.133347 (0.208046 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:03:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.162851 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:03:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/17 01:03:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24400394964292627\n",
      "\u001b[32m[12/17 01:03:20 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is0.24400, better than last best score 0.23121 @ iteration 483.\n",
      "\u001b[32m[12/17 01:03:42 d2.utils.events]: \u001b[0m eta: 3:20:25  iter: 979  total_loss: 1.509  loss_cls: 0.3617  loss_box_reg: 0.5031  loss_mask: 0.2899  loss_rpn_cls: 0.09383  loss_rpn_loc: 0.1954  time: 1.5666  data_time: 0.7317  lr: 0.00095506  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:04:14 d2.utils.events]: \u001b[0m eta: 3:21:00  iter: 999  total_loss: 1.488  loss_cls: 0.3501  loss_box_reg: 0.538  loss_mask: 0.3005  loss_rpn_cls: 0.09658  loss_rpn_loc: 0.198  time: 1.5675  data_time: 0.2805  lr: 0.00097455  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:04:57 d2.utils.events]: \u001b[0m eta: 3:23:06  iter: 1019  total_loss: 1.569  loss_cls: 0.3818  loss_box_reg: 0.5265  loss_mask: 0.3248  loss_rpn_cls: 0.1138  loss_rpn_loc: 0.2443  time: 1.5790  data_time: 0.9322  lr: 0.0009746  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:05:40 d2.utils.events]: \u001b[0m eta: 3:25:57  iter: 1039  total_loss: 1.562  loss_cls: 0.3343  loss_box_reg: 0.5383  loss_mask: 0.3148  loss_rpn_cls: 0.09627  loss_rpn_loc: 0.2199  time: 1.5899  data_time: 0.6317  lr: 0.0009736  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:06:13 d2.utils.events]: \u001b[0m eta: 3:27:48  iter: 1059  total_loss: 1.386  loss_cls: 0.321  loss_box_reg: 0.5024  loss_mask: 0.3028  loss_rpn_cls: 0.07282  loss_rpn_loc: 0.1859  time: 1.5907  data_time: 0.2814  lr: 0.00097258  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:06:55 d2.utils.events]: \u001b[0m eta: 3:28:42  iter: 1079  total_loss: 1.603  loss_cls: 0.3806  loss_box_reg: 0.53  loss_mask: 0.3101  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2295  time: 1.6004  data_time: 0.8680  lr: 0.00097155  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:07:32 d2.utils.events]: \u001b[0m eta: 3:29:42  iter: 1099  total_loss: 1.493  loss_cls: 0.3502  loss_box_reg: 0.5315  loss_mask: 0.2951  loss_rpn_cls: 0.07792  loss_rpn_loc: 0.2241  time: 1.6050  data_time: 0.3276  lr: 0.00097049  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:08:04 d2.utils.events]: \u001b[0m eta: 3:31:00  iter: 1119  total_loss: 1.474  loss_cls: 0.3475  loss_box_reg: 0.5498  loss_mask: 0.3012  loss_rpn_cls: 0.08275  loss_rpn_loc: 0.1943  time: 1.6049  data_time: 0.3202  lr: 0.00096942  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:08:39 d2.utils.events]: \u001b[0m eta: 3:31:55  iter: 1139  total_loss: 1.473  loss_cls: 0.3343  loss_box_reg: 0.5213  loss_mask: 0.2947  loss_rpn_cls: 0.09696  loss_rpn_loc: 0.1874  time: 1.6076  data_time: 0.5039  lr: 0.00096833  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:09:12 d2.utils.events]: \u001b[0m eta: 3:31:49  iter: 1159  total_loss: 1.486  loss_cls: 0.3692  loss_box_reg: 0.5248  loss_mask: 0.3111  loss_rpn_cls: 0.08442  loss_rpn_loc: 0.1979  time: 1.6084  data_time: 0.5771  lr: 0.00096722  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:09:45 d2.utils.events]: \u001b[0m eta: 3:31:28  iter: 1179  total_loss: 1.559  loss_cls: 0.3916  loss_box_reg: 0.5235  loss_mask: 0.3064  loss_rpn_cls: 0.09624  loss_rpn_loc: 0.2179  time: 1.6088  data_time: 0.2475  lr: 0.00096609  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:10:21 d2.utils.events]: \u001b[0m eta: 3:30:52  iter: 1199  total_loss: 1.503  loss_cls: 0.3582  loss_box_reg: 0.557  loss_mask: 0.3121  loss_rpn_cls: 0.07924  loss_rpn_loc: 0.2038  time: 1.6123  data_time: 0.4310  lr: 0.00096495  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:10:36 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:10:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/17 01:10:36 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 01:10:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.73 MiB\n",
      "\u001b[32m[12/17 01:10:37 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:10:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/17 01:10:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0017 s/iter. Inference: 0.1852 s/iter. Eval: 0.0251 s/iter. Total: 0.2120 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/17 01:10:44 d2.evaluation.evaluator]: \u001b[0mInference done 33/121. Dataloading: 0.0017 s/iter. Inference: 0.1906 s/iter. Eval: 0.0320 s/iter. Total: 0.2245 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/17 01:10:49 d2.evaluation.evaluator]: \u001b[0mInference done 55/121. Dataloading: 0.0016 s/iter. Inference: 0.1928 s/iter. Eval: 0.0330 s/iter. Total: 0.2276 s/iter. ETA=0:00:15\n",
      "\u001b[32m[12/17 01:10:55 d2.evaluation.evaluator]: \u001b[0mInference done 79/121. Dataloading: 0.0018 s/iter. Inference: 0.1837 s/iter. Eval: 0.0366 s/iter. Total: 0.2222 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/17 01:11:00 d2.evaluation.evaluator]: \u001b[0mInference done 109/121. Dataloading: 0.0018 s/iter. Inference: 0.1674 s/iter. Eval: 0.0372 s/iter. Total: 0.2066 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/17 01:11:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.729857 (0.204568 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:11:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.165600 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:11:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/17 01:11:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24135727632586915\n",
      "\u001b[32m[12/17 01:11:02 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.24136, not better than best score 0.24400 @ iteration 967.\n",
      "\u001b[32m[12/17 01:11:22 d2.utils.events]: \u001b[0m eta: 3:30:30  iter: 1219  total_loss: 1.534  loss_cls: 0.3814  loss_box_reg: 0.5423  loss_mask: 0.3033  loss_rpn_cls: 0.09135  loss_rpn_loc: 0.1903  time: 1.6140  data_time: 0.2658  lr: 0.00096378  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:11:54 d2.utils.events]: \u001b[0m eta: 3:31:08  iter: 1239  total_loss: 1.542  loss_cls: 0.3791  loss_box_reg: 0.5274  loss_mask: 0.3018  loss_rpn_cls: 0.109  loss_rpn_loc: 0.209  time: 1.6138  data_time: 0.1692  lr: 0.0009626  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:12:36 d2.utils.events]: \u001b[0m eta: 3:31:58  iter: 1259  total_loss: 1.572  loss_cls: 0.3823  loss_box_reg: 0.5449  loss_mask: 0.3235  loss_rpn_cls: 0.09402  loss_rpn_loc: 0.2337  time: 1.6212  data_time: 0.5343  lr: 0.0009614  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:13:17 d2.utils.events]: \u001b[0m eta: 3:32:34  iter: 1279  total_loss: 1.503  loss_cls: 0.3741  loss_box_reg: 0.5135  loss_mask: 0.295  loss_rpn_cls: 0.09881  loss_rpn_loc: 0.1984  time: 1.6279  data_time: 0.4747  lr: 0.00096018  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:13:53 d2.utils.events]: \u001b[0m eta: 3:32:00  iter: 1299  total_loss: 1.395  loss_cls: 0.3171  loss_box_reg: 0.5231  loss_mask: 0.2926  loss_rpn_cls: 0.06639  loss_rpn_loc: 0.1907  time: 1.6306  data_time: 0.2967  lr: 0.00095894  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:14:23 d2.utils.events]: \u001b[0m eta: 3:32:27  iter: 1319  total_loss: 1.473  loss_cls: 0.3596  loss_box_reg: 0.5504  loss_mask: 0.314  loss_rpn_cls: 0.07338  loss_rpn_loc: 0.1992  time: 1.6292  data_time: 0.0280  lr: 0.00095768  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:14:59 d2.utils.events]: \u001b[0m eta: 3:32:26  iter: 1339  total_loss: 1.478  loss_cls: 0.3394  loss_box_reg: 0.5355  loss_mask: 0.3079  loss_rpn_cls: 0.09736  loss_rpn_loc: 0.2073  time: 1.6314  data_time: 0.3247  lr: 0.00095641  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:15:36 d2.utils.events]: \u001b[0m eta: 3:33:53  iter: 1359  total_loss: 1.412  loss_cls: 0.3054  loss_box_reg: 0.4914  loss_mask: 0.2862  loss_rpn_cls: 0.08147  loss_rpn_loc: 0.2043  time: 1.6345  data_time: 0.2087  lr: 0.00095512  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:16:20 d2.utils.events]: \u001b[0m eta: 3:34:21  iter: 1379  total_loss: 1.45  loss_cls: 0.3589  loss_box_reg: 0.5113  loss_mask: 0.3018  loss_rpn_cls: 0.07623  loss_rpn_loc: 0.2106  time: 1.6425  data_time: 0.5718  lr: 0.00095381  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:17:00 d2.utils.events]: \u001b[0m eta: 3:35:30  iter: 1399  total_loss: 1.408  loss_cls: 0.3491  loss_box_reg: 0.5108  loss_mask: 0.3005  loss_rpn_cls: 0.08762  loss_rpn_loc: 0.2  time: 1.6479  data_time: 0.3760  lr: 0.00095248  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:17:37 d2.utils.events]: \u001b[0m eta: 3:35:17  iter: 1419  total_loss: 1.425  loss_cls: 0.3428  loss_box_reg: 0.5064  loss_mask: 0.2931  loss_rpn_cls: 0.09948  loss_rpn_loc: 0.2084  time: 1.6506  data_time: 0.3364  lr: 0.00095113  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:18:07 d2.utils.events]: \u001b[0m eta: 3:34:57  iter: 1439  total_loss: 1.499  loss_cls: 0.3531  loss_box_reg: 0.5144  loss_mask: 0.2981  loss_rpn_cls: 0.09986  loss_rpn_loc: 0.2193  time: 1.6483  data_time: 0.3688  lr: 0.00094977  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:18:30 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:18:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/17 01:18:30 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 01:18:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.73 MiB\n",
      "\u001b[32m[12/17 01:18:31 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:18:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/17 01:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0018 s/iter. Inference: 0.2297 s/iter. Eval: 0.0338 s/iter. Total: 0.2654 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/17 01:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 42/121. Dataloading: 0.0017 s/iter. Inference: 0.1288 s/iter. Eval: 0.0476 s/iter. Total: 0.1783 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/17 01:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 73/121. Dataloading: 0.0019 s/iter. Inference: 0.1202 s/iter. Eval: 0.0502 s/iter. Total: 0.1724 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/17 01:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 99/121. Dataloading: 0.0019 s/iter. Inference: 0.1242 s/iter. Eval: 0.0529 s/iter. Total: 0.1790 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/17 01:18:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.434138 (0.184777 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:18:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.132128 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:18:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/17 01:18:54 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25799940224842904\n",
      "\u001b[32m[12/17 01:18:57 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is0.25800, better than last best score 0.24400 @ iteration 967.\n",
      "\u001b[32m[12/17 01:19:13 d2.utils.events]: \u001b[0m eta: 3:34:54  iter: 1459  total_loss: 1.547  loss_cls: 0.3574  loss_box_reg: 0.5088  loss_mask: 0.3071  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.2116  time: 1.6522  data_time: 0.5026  lr: 0.00094839  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:19:36 d2.utils.events]: \u001b[0m eta: 3:34:21  iter: 1479  total_loss: 1.425  loss_cls: 0.3556  loss_box_reg: 0.5314  loss_mask: 0.2853  loss_rpn_cls: 0.0657  loss_rpn_loc: 0.1987  time: 1.6459  data_time: 0.2194  lr: 0.00094699  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:20:17 d2.utils.events]: \u001b[0m eta: 3:33:54  iter: 1499  total_loss: 1.569  loss_cls: 0.3661  loss_box_reg: 0.5216  loss_mask: 0.3053  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.2161  time: 1.6509  data_time: 1.1072  lr: 0.00094557  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:20:44 d2.utils.events]: \u001b[0m eta: 3:33:04  iter: 1519  total_loss: 1.372  loss_cls: 0.3167  loss_box_reg: 0.5228  loss_mask: 0.2917  loss_rpn_cls: 0.06785  loss_rpn_loc: 0.1776  time: 1.6470  data_time: 0.3501  lr: 0.00094414  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:21:15 d2.utils.events]: \u001b[0m eta: 3:32:21  iter: 1539  total_loss: 1.329  loss_cls: 0.288  loss_box_reg: 0.5071  loss_mask: 0.3074  loss_rpn_cls: 0.08799  loss_rpn_loc: 0.1918  time: 1.6459  data_time: 0.4941  lr: 0.00094269  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:21:42 d2.utils.events]: \u001b[0m eta: 3:31:29  iter: 1559  total_loss: 1.486  loss_cls: 0.3631  loss_box_reg: 0.5451  loss_mask: 0.3083  loss_rpn_cls: 0.09475  loss_rpn_loc: 0.2007  time: 1.6422  data_time: 0.2450  lr: 0.00094122  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:22:18 d2.utils.events]: \u001b[0m eta: 3:31:16  iter: 1579  total_loss: 1.457  loss_cls: 0.3279  loss_box_reg: 0.5159  loss_mask: 0.316  loss_rpn_cls: 0.09149  loss_rpn_loc: 0.2047  time: 1.6437  data_time: 0.9498  lr: 0.00093973  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:22:51 d2.utils.events]: \u001b[0m eta: 3:30:50  iter: 1599  total_loss: 1.407  loss_cls: 0.3454  loss_box_reg: 0.4947  loss_mask: 0.2984  loss_rpn_cls: 0.0893  loss_rpn_loc: 0.1962  time: 1.6443  data_time: 0.6176  lr: 0.00093823  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:23:24 d2.utils.events]: \u001b[0m eta: 3:30:26  iter: 1619  total_loss: 1.536  loss_cls: 0.3706  loss_box_reg: 0.5347  loss_mask: 0.3121  loss_rpn_cls: 0.1159  loss_rpn_loc: 0.2204  time: 1.6443  data_time: 0.2925  lr: 0.00093671  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:23:58 d2.utils.events]: \u001b[0m eta: 3:29:57  iter: 1639  total_loss: 1.504  loss_cls: 0.3288  loss_box_reg: 0.5162  loss_mask: 0.2947  loss_rpn_cls: 0.07416  loss_rpn_loc: 0.1907  time: 1.6448  data_time: 0.6818  lr: 0.00093517  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:24:43 d2.utils.events]: \u001b[0m eta: 3:29:49  iter: 1659  total_loss: 1.55  loss_cls: 0.3441  loss_box_reg: 0.5048  loss_mask: 0.3056  loss_rpn_cls: 0.1348  loss_rpn_loc: 0.2146  time: 1.6520  data_time: 0.9690  lr: 0.00093361  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:25:13 d2.utils.events]: \u001b[0m eta: 3:29:22  iter: 1679  total_loss: 1.445  loss_cls: 0.3064  loss_box_reg: 0.5197  loss_mask: 0.2777  loss_rpn_cls: 0.07763  loss_rpn_loc: 0.2057  time: 1.6503  data_time: 0.4737  lr: 0.00093204  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:25:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:25:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/17 01:25:40 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 01:25:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.73 MiB\n",
      "\u001b[32m[12/17 01:25:40 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:25:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/17 01:25:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0017 s/iter. Inference: 0.0989 s/iter. Eval: 0.0376 s/iter. Total: 0.1381 s/iter. ETA=0:00:15\n",
      "\u001b[32m[12/17 01:25:48 d2.evaluation.evaluator]: \u001b[0mInference done 32/121. Dataloading: 0.0017 s/iter. Inference: 0.1706 s/iter. Eval: 0.0448 s/iter. Total: 0.2173 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/17 01:25:53 d2.evaluation.evaluator]: \u001b[0mInference done 47/121. Dataloading: 0.0016 s/iter. Inference: 0.2200 s/iter. Eval: 0.0404 s/iter. Total: 0.2622 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/17 01:25:58 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0016 s/iter. Inference: 0.2430 s/iter. Eval: 0.0380 s/iter. Total: 0.2828 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/17 01:26:03 d2.evaluation.evaluator]: \u001b[0mInference done 77/121. Dataloading: 0.0016 s/iter. Inference: 0.2574 s/iter. Eval: 0.0382 s/iter. Total: 0.2975 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/17 01:26:08 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0016 s/iter. Inference: 0.2575 s/iter. Eval: 0.0393 s/iter. Total: 0.2986 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/17 01:26:13 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0016 s/iter. Inference: 0.2598 s/iter. Eval: 0.0379 s/iter. Total: 0.2995 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/17 01:26:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.011091 (0.293199 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:26:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:29 (0.252737 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:26:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/17 01:26:16 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.25706002487367474\n",
      "\u001b[32m[12/17 01:26:16 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.25706, not better than best score 0.25800 @ iteration 1451.\n",
      "\u001b[32m[12/17 01:26:26 d2.utils.events]: \u001b[0m eta: 3:29:01  iter: 1699  total_loss: 1.385  loss_cls: 0.2866  loss_box_reg: 0.4928  loss_mask: 0.3035  loss_rpn_cls: 0.06808  loss_rpn_loc: 0.2105  time: 1.6524  data_time: 0.9165  lr: 0.00093045  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:26:55 d2.utils.events]: \u001b[0m eta: 3:27:37  iter: 1719  total_loss: 1.425  loss_cls: 0.3712  loss_box_reg: 0.4985  loss_mask: 0.304  loss_rpn_cls: 0.07509  loss_rpn_loc: 0.2  time: 1.6498  data_time: 0.4335  lr: 0.00092884  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:27:27 d2.utils.events]: \u001b[0m eta: 3:26:17  iter: 1739  total_loss: 1.56  loss_cls: 0.3791  loss_box_reg: 0.5493  loss_mask: 0.3178  loss_rpn_cls: 0.08851  loss_rpn_loc: 0.2245  time: 1.6491  data_time: 0.6820  lr: 0.00092722  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:28:08 d2.utils.events]: \u001b[0m eta: 3:26:16  iter: 1759  total_loss: 1.394  loss_cls: 0.304  loss_box_reg: 0.4863  loss_mask: 0.3028  loss_rpn_cls: 0.08994  loss_rpn_loc: 0.2164  time: 1.6539  data_time: 1.1712  lr: 0.00092558  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:28:38 d2.utils.events]: \u001b[0m eta: 3:25:22  iter: 1779  total_loss: 1.535  loss_cls: 0.3682  loss_box_reg: 0.5689  loss_mask: 0.2998  loss_rpn_cls: 0.08796  loss_rpn_loc: 0.1953  time: 1.6522  data_time: 0.3264  lr: 0.00092392  max_mem: 6101M\n",
      "\u001b[32m[12/17 01:29:14 d2.utils.events]: \u001b[0m eta: 3:24:01  iter: 1799  total_loss: 1.295  loss_cls: 0.2883  loss_box_reg: 0.4739  loss_mask: 0.2921  loss_rpn_cls: 0.05463  loss_rpn_loc: 0.1711  time: 1.6539  data_time: 1.1088  lr: 0.00092225  max_mem: 6217M\n",
      "\u001b[32m[12/17 01:29:45 d2.utils.events]: \u001b[0m eta: 3:23:23  iter: 1819  total_loss: 1.434  loss_cls: 0.3361  loss_box_reg: 0.4932  loss_mask: 0.3084  loss_rpn_cls: 0.09592  loss_rpn_loc: 0.1976  time: 1.6528  data_time: 0.9128  lr: 0.00092056  max_mem: 6217M\n",
      "\u001b[32m[12/17 01:30:21 d2.utils.events]: \u001b[0m eta: 3:23:02  iter: 1839  total_loss: 1.545  loss_cls: 0.3417  loss_box_reg: 0.4986  loss_mask: 0.3012  loss_rpn_cls: 0.09853  loss_rpn_loc: 0.2152  time: 1.6544  data_time: 1.1414  lr: 0.00091885  max_mem: 6217M\n",
      "\u001b[32m[12/17 01:31:01 d2.utils.events]: \u001b[0m eta: 3:22:20  iter: 1859  total_loss: 1.52  loss_cls: 0.3581  loss_box_reg: 0.5237  loss_mask: 0.304  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.2171  time: 1.6581  data_time: 1.3667  lr: 0.00091713  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:31:26 d2.utils.events]: \u001b[0m eta: 3:21:21  iter: 1879  total_loss: 1.418  loss_cls: 0.322  loss_box_reg: 0.5028  loss_mask: 0.2964  loss_rpn_cls: 0.07907  loss_rpn_loc: 0.2057  time: 1.6538  data_time: 0.7250  lr: 0.00091539  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:31:54 d2.utils.events]: \u001b[0m eta: 3:20:26  iter: 1899  total_loss: 1.415  loss_cls: 0.3265  loss_box_reg: 0.5368  loss_mask: 0.2925  loss_rpn_cls: 0.07206  loss_rpn_loc: 0.1972  time: 1.6511  data_time: 0.5608  lr: 0.00091363  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:32:28 d2.utils.events]: \u001b[0m eta: 3:20:13  iter: 1919  total_loss: 1.449  loss_cls: 0.322  loss_box_reg: 0.5057  loss_mask: 0.2992  loss_rpn_cls: 0.08096  loss_rpn_loc: 0.2043  time: 1.6514  data_time: 0.9799  lr: 0.00091186  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:32:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:32:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/17 01:32:54 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 01:32:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.73 MiB\n",
      "\u001b[32m[12/17 01:32:54 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:32:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/17 01:32:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0016 s/iter. Inference: 0.0664 s/iter. Eval: 0.0327 s/iter. Total: 0.1007 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/17 01:33:02 d2.evaluation.evaluator]: \u001b[0mInference done 37/121. Dataloading: 0.0018 s/iter. Inference: 0.1316 s/iter. Eval: 0.0444 s/iter. Total: 0.1780 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/17 01:33:07 d2.evaluation.evaluator]: \u001b[0mInference done 56/121. Dataloading: 0.0018 s/iter. Inference: 0.1674 s/iter. Eval: 0.0416 s/iter. Total: 0.2109 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/17 01:33:12 d2.evaluation.evaluator]: \u001b[0mInference done 75/121. Dataloading: 0.0017 s/iter. Inference: 0.1849 s/iter. Eval: 0.0414 s/iter. Total: 0.2282 s/iter. ETA=0:00:10\n",
      "\u001b[32m[12/17 01:33:17 d2.evaluation.evaluator]: \u001b[0mInference done 94/121. Dataloading: 0.0017 s/iter. Inference: 0.1923 s/iter. Eval: 0.0424 s/iter. Total: 0.2366 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/17 01:33:22 d2.evaluation.evaluator]: \u001b[0mInference done 113/121. Dataloading: 0.0017 s/iter. Inference: 0.2006 s/iter. Eval: 0.0404 s/iter. Total: 0.2428 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/17 01:33:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.139441 (0.242581 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:33:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:23 (0.199874 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:33:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/17 01:33:24 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26526162838433426\n",
      "\u001b[32m[12/17 01:33:27 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is0.26526, better than last best score 0.25800 @ iteration 1451.\n",
      "\u001b[32m[12/17 01:33:30 d2.utils.events]: \u001b[0m eta: 3:19:27  iter: 1939  total_loss: 1.396  loss_cls: 0.3096  loss_box_reg: 0.5403  loss_mask: 0.296  loss_rpn_cls: 0.07355  loss_rpn_loc: 0.1898  time: 1.6490  data_time: 0.8445  lr: 0.00091007  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:34:05 d2.utils.events]: \u001b[0m eta: 3:19:13  iter: 1959  total_loss: 1.45  loss_cls: 0.3284  loss_box_reg: 0.5052  loss_mask: 0.3016  loss_rpn_cls: 0.08319  loss_rpn_loc: 0.1992  time: 1.6502  data_time: 1.1933  lr: 0.00090826  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:34:36 d2.utils.events]: \u001b[0m eta: 3:17:42  iter: 1979  total_loss: 1.56  loss_cls: 0.378  loss_box_reg: 0.537  loss_mask: 0.3085  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.207  time: 1.6492  data_time: 0.8342  lr: 0.00090644  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:35:11 d2.utils.events]: \u001b[0m eta: 3:16:48  iter: 1999  total_loss: 1.338  loss_cls: 0.2967  loss_box_reg: 0.5139  loss_mask: 0.3052  loss_rpn_cls: 0.06234  loss_rpn_loc: 0.1698  time: 1.6499  data_time: 0.8413  lr: 0.0009046  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:35:41 d2.utils.events]: \u001b[0m eta: 3:16:08  iter: 2019  total_loss: 1.431  loss_cls: 0.3377  loss_box_reg: 0.5055  loss_mask: 0.2903  loss_rpn_cls: 0.08704  loss_rpn_loc: 0.2011  time: 1.6488  data_time: 0.3944  lr: 0.00090275  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:36:12 d2.utils.events]: \u001b[0m eta: 3:15:01  iter: 2039  total_loss: 1.542  loss_cls: 0.3963  loss_box_reg: 0.524  loss_mask: 0.3066  loss_rpn_cls: 0.09271  loss_rpn_loc: 0.2093  time: 1.6475  data_time: 0.6378  lr: 0.00090088  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:36:47 d2.utils.events]: \u001b[0m eta: 3:13:55  iter: 2059  total_loss: 1.438  loss_cls: 0.3273  loss_box_reg: 0.5189  loss_mask: 0.3095  loss_rpn_cls: 0.06926  loss_rpn_loc: 0.1951  time: 1.6486  data_time: 0.5193  lr: 0.00089899  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:37:23 d2.utils.events]: \u001b[0m eta: 3:13:02  iter: 2079  total_loss: 1.48  loss_cls: 0.3628  loss_box_reg: 0.5124  loss_mask: 0.3006  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.2075  time: 1.6502  data_time: 0.4699  lr: 0.00089709  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:37:56 d2.utils.events]: \u001b[0m eta: 3:11:51  iter: 2099  total_loss: 1.376  loss_cls: 0.2983  loss_box_reg: 0.5005  loss_mask: 0.2965  loss_rpn_cls: 0.05949  loss_rpn_loc: 0.1941  time: 1.6502  data_time: 0.4431  lr: 0.00089517  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:38:31 d2.utils.events]: \u001b[0m eta: 3:11:42  iter: 2119  total_loss: 1.376  loss_cls: 0.3152  loss_box_reg: 0.5332  loss_mask: 0.3075  loss_rpn_cls: 0.06852  loss_rpn_loc: 0.1931  time: 1.6510  data_time: 0.3616  lr: 0.00089324  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:39:08 d2.utils.events]: \u001b[0m eta: 3:10:29  iter: 2139  total_loss: 1.377  loss_cls: 0.3214  loss_box_reg: 0.4774  loss_mask: 0.2964  loss_rpn_cls: 0.07282  loss_rpn_loc: 0.2115  time: 1.6526  data_time: 0.6504  lr: 0.00089129  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:39:38 d2.utils.events]: \u001b[0m eta: 3:09:27  iter: 2159  total_loss: 1.487  loss_cls: 0.3546  loss_box_reg: 0.507  loss_mask: 0.3029  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2062  time: 1.6514  data_time: 0.7800  lr: 0.00088933  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:40:10 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:40:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/17 01:40:11 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 01:40:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.73 MiB\n",
      "\u001b[32m[12/17 01:40:11 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:40:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/17 01:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0032 s/iter. Inference: 0.1000 s/iter. Eval: 0.0418 s/iter. Total: 0.1450 s/iter. ETA=0:00:15\n",
      "\u001b[32m[12/17 01:40:19 d2.evaluation.evaluator]: \u001b[0mInference done 45/121. Dataloading: 0.0023 s/iter. Inference: 0.1002 s/iter. Eval: 0.0480 s/iter. Total: 0.1507 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/17 01:40:24 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0021 s/iter. Inference: 0.1546 s/iter. Eval: 0.0428 s/iter. Total: 0.1996 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/17 01:40:29 d2.evaluation.evaluator]: \u001b[0mInference done 76/121. Dataloading: 0.0020 s/iter. Inference: 0.1867 s/iter. Eval: 0.0404 s/iter. Total: 0.2293 s/iter. ETA=0:00:10\n",
      "\u001b[32m[12/17 01:40:34 d2.evaluation.evaluator]: \u001b[0mInference done 91/121. Dataloading: 0.0020 s/iter. Inference: 0.2077 s/iter. Eval: 0.0390 s/iter. Total: 0.2489 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/17 01:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0020 s/iter. Inference: 0.1994 s/iter. Eval: 0.0376 s/iter. Total: 0.2393 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/17 01:40:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.592396 (0.237865 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:40:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.197320 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:40:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/17 01:40:40 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.250392225738692\n",
      "\u001b[32m[12/17 01:40:40 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.25039, not better than best score 0.26526 @ iteration 1935.\n",
      "\u001b[32m[12/17 01:40:42 d2.utils.events]: \u001b[0m eta: 3:08:40  iter: 2179  total_loss: 1.474  loss_cls: 0.3398  loss_box_reg: 0.5347  loss_mask: 0.3038  loss_rpn_cls: 0.06986  loss_rpn_loc: 0.206  time: 1.6518  data_time: 0.4692  lr: 0.00088735  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:41:17 d2.utils.events]: \u001b[0m eta: 3:07:59  iter: 2199  total_loss: 1.426  loss_cls: 0.2957  loss_box_reg: 0.5059  loss_mask: 0.3184  loss_rpn_cls: 0.08002  loss_rpn_loc: 0.2022  time: 1.6530  data_time: 0.9476  lr: 0.00088536  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:41:41 d2.utils.events]: \u001b[0m eta: 3:06:26  iter: 2219  total_loss: 1.363  loss_cls: 0.2707  loss_box_reg: 0.501  loss_mask: 0.296  loss_rpn_cls: 0.06528  loss_rpn_loc: 0.19  time: 1.6488  data_time: 0.2706  lr: 0.00088335  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:42:10 d2.utils.events]: \u001b[0m eta: 3:03:15  iter: 2239  total_loss: 1.461  loss_cls: 0.306  loss_box_reg: 0.5037  loss_mask: 0.3069  loss_rpn_cls: 0.08854  loss_rpn_loc: 0.196  time: 1.6469  data_time: 0.7791  lr: 0.00088132  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:42:45 d2.utils.events]: \u001b[0m eta: 3:01:58  iter: 2259  total_loss: 1.463  loss_cls: 0.3515  loss_box_reg: 0.525  loss_mask: 0.2871  loss_rpn_cls: 0.07664  loss_rpn_loc: 0.1907  time: 1.6476  data_time: 0.8419  lr: 0.00087928  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:43:16 d2.utils.events]: \u001b[0m eta: 2:58:45  iter: 2279  total_loss: 1.447  loss_cls: 0.3307  loss_box_reg: 0.5245  loss_mask: 0.3048  loss_rpn_cls: 0.09967  loss_rpn_loc: 0.2028  time: 1.6468  data_time: 0.8892  lr: 0.00087723  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:43:43 d2.utils.events]: \u001b[0m eta: 2:56:33  iter: 2299  total_loss: 1.457  loss_cls: 0.3515  loss_box_reg: 0.5039  loss_mask: 0.2977  loss_rpn_cls: 0.07278  loss_rpn_loc: 0.2126  time: 1.6442  data_time: 0.6857  lr: 0.00087516  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:44:09 d2.utils.events]: \u001b[0m eta: 2:53:15  iter: 2319  total_loss: 1.366  loss_cls: 0.2863  loss_box_reg: 0.5196  loss_mask: 0.2933  loss_rpn_cls: 0.05099  loss_rpn_loc: 0.1889  time: 1.6413  data_time: 0.3971  lr: 0.00087308  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:44:26 d2.utils.events]: \u001b[0m eta: 2:50:29  iter: 2339  total_loss: 1.47  loss_cls: 0.331  loss_box_reg: 0.5349  loss_mask: 0.3137  loss_rpn_cls: 0.08168  loss_rpn_loc: 0.1945  time: 1.6346  data_time: 0.2947  lr: 0.00087098  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:45:01 d2.utils.events]: \u001b[0m eta: 2:47:34  iter: 2359  total_loss: 1.446  loss_cls: 0.3365  loss_box_reg: 0.5071  loss_mask: 0.2952  loss_rpn_cls: 0.07245  loss_rpn_loc: 0.1906  time: 1.6357  data_time: 1.1294  lr: 0.00086886  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:45:32 d2.utils.events]: \u001b[0m eta: 2:43:43  iter: 2379  total_loss: 1.473  loss_cls: 0.332  loss_box_reg: 0.4951  loss_mask: 0.3054  loss_rpn_cls: 0.08817  loss_rpn_loc: 0.2262  time: 1.6348  data_time: 1.0059  lr: 0.00086673  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:46:08 d2.utils.events]: \u001b[0m eta: 2:39:22  iter: 2399  total_loss: 1.463  loss_cls: 0.359  loss_box_reg: 0.5249  loss_mask: 0.3118  loss_rpn_cls: 0.08804  loss_rpn_loc: 0.2041  time: 1.6361  data_time: 1.1712  lr: 0.00086459  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:46:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:46:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/17 01:46:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 01:46:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.73 MiB\n",
      "\u001b[32m[12/17 01:46:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:46:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/17 01:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0021 s/iter. Inference: 0.0604 s/iter. Eval: 0.0265 s/iter. Total: 0.0891 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/17 01:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 32/121. Dataloading: 0.0023 s/iter. Inference: 0.1705 s/iter. Eval: 0.0370 s/iter. Total: 0.2101 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/17 01:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0022 s/iter. Inference: 0.1504 s/iter. Eval: 0.0408 s/iter. Total: 0.1934 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/17 01:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0023 s/iter. Inference: 0.1280 s/iter. Eval: 0.0460 s/iter. Total: 0.1763 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/17 01:47:01 d2.evaluation.evaluator]: \u001b[0mInference done 119/121. Dataloading: 0.0022 s/iter. Inference: 0.1377 s/iter. Eval: 0.0436 s/iter. Total: 0.1836 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/17 01:47:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.518069 (0.185501 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:47:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.138903 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:47:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/17 01:47:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2497056326516182\n",
      "\u001b[32m[12/17 01:47:02 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.24971, not better than best score 0.26526 @ iteration 1935.\n",
      "\u001b[32m[12/17 01:47:02 d2.utils.events]: \u001b[0m eta: 2:34:52  iter: 2419  total_loss: 1.428  loss_cls: 0.3319  loss_box_reg: 0.5045  loss_mask: 0.2968  loss_rpn_cls: 0.07614  loss_rpn_loc: 0.2031  time: 1.6350  data_time: 0.8305  lr: 0.00086243  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:47:28 d2.utils.events]: \u001b[0m eta: 2:34:03  iter: 2439  total_loss: 1.392  loss_cls: 0.3112  loss_box_reg: 0.5009  loss_mask: 0.3067  loss_rpn_cls: 0.0624  loss_rpn_loc: 0.1802  time: 1.6321  data_time: 0.4671  lr: 0.00086026  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:48:06 d2.utils.events]: \u001b[0m eta: 2:31:24  iter: 2459  total_loss: 1.424  loss_cls: 0.3349  loss_box_reg: 0.5152  loss_mask: 0.3075  loss_rpn_cls: 0.07939  loss_rpn_loc: 0.1983  time: 1.6345  data_time: 1.1524  lr: 0.00085808  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:48:40 d2.utils.events]: \u001b[0m eta: 2:29:15  iter: 2479  total_loss: 1.417  loss_cls: 0.3317  loss_box_reg: 0.4958  loss_mask: 0.3019  loss_rpn_cls: 0.07313  loss_rpn_loc: 0.2009  time: 1.6349  data_time: 1.1876  lr: 0.00085588  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:49:06 d2.utils.events]: \u001b[0m eta: 2:27:19  iter: 2499  total_loss: 1.467  loss_cls: 0.3469  loss_box_reg: 0.5095  loss_mask: 0.2894  loss_rpn_cls: 0.06798  loss_rpn_loc: 0.2076  time: 1.6323  data_time: 0.7669  lr: 0.00085366  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:49:42 d2.utils.events]: \u001b[0m eta: 2:26:55  iter: 2519  total_loss: 1.431  loss_cls: 0.3477  loss_box_reg: 0.4871  loss_mask: 0.2998  loss_rpn_cls: 0.08116  loss_rpn_loc: 0.1895  time: 1.6334  data_time: 1.3652  lr: 0.00085144  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:50:06 d2.utils.events]: \u001b[0m eta: 2:27:14  iter: 2539  total_loss: 1.414  loss_cls: 0.3229  loss_box_reg: 0.5145  loss_mask: 0.3017  loss_rpn_cls: 0.08326  loss_rpn_loc: 0.1988  time: 1.6304  data_time: 0.4692  lr: 0.0008492  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:50:36 d2.utils.events]: \u001b[0m eta: 2:26:50  iter: 2559  total_loss: 1.52  loss_cls: 0.3292  loss_box_reg: 0.5157  loss_mask: 0.3129  loss_rpn_cls: 0.08684  loss_rpn_loc: 0.2065  time: 1.6291  data_time: 0.8853  lr: 0.00084694  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:51:07 d2.utils.events]: \u001b[0m eta: 2:25:58  iter: 2579  total_loss: 1.516  loss_cls: 0.3621  loss_box_reg: 0.5016  loss_mask: 0.3119  loss_rpn_cls: 0.08663  loss_rpn_loc: 0.2101  time: 1.6284  data_time: 0.9915  lr: 0.00084467  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:51:40 d2.utils.events]: \u001b[0m eta: 2:25:08  iter: 2599  total_loss: 1.369  loss_cls: 0.321  loss_box_reg: 0.5148  loss_mask: 0.2949  loss_rpn_cls: 0.07904  loss_rpn_loc: 0.1977  time: 1.6286  data_time: 1.0070  lr: 0.00084239  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:52:10 d2.utils.events]: \u001b[0m eta: 2:22:24  iter: 2619  total_loss: 1.464  loss_cls: 0.3338  loss_box_reg: 0.5074  loss_mask: 0.2856  loss_rpn_cls: 0.08478  loss_rpn_loc: 0.2117  time: 1.6279  data_time: 0.9525  lr: 0.00084009  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:52:42 d2.utils.events]: \u001b[0m eta: 2:21:56  iter: 2639  total_loss: 1.395  loss_cls: 0.3005  loss_box_reg: 0.502  loss_mask: 0.2966  loss_rpn_cls: 0.07885  loss_rpn_loc: 0.1984  time: 1.6276  data_time: 0.9733  lr: 0.00083778  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:53:03 d2.utils.events]: \u001b[0m eta: 2:16:35  iter: 2659  total_loss: 1.41  loss_cls: 0.3221  loss_box_reg: 0.5189  loss_mask: 0.3098  loss_rpn_cls: 0.06247  loss_rpn_loc: 0.1851  time: 1.6232  data_time: 0.2985  lr: 0.00083546  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:53:05 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:53:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/17 01:53:05 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 01:53:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.73 MiB\n",
      "\u001b[32m[12/17 01:53:06 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 01:53:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/17 01:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0016 s/iter. Inference: 0.0889 s/iter. Eval: 0.0343 s/iter. Total: 0.1248 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/17 01:53:13 d2.evaluation.evaluator]: \u001b[0mInference done 44/121. Dataloading: 0.0018 s/iter. Inference: 0.1020 s/iter. Eval: 0.0495 s/iter. Total: 0.1534 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/17 01:53:18 d2.evaluation.evaluator]: \u001b[0mInference done 59/121. Dataloading: 0.0017 s/iter. Inference: 0.1600 s/iter. Eval: 0.0451 s/iter. Total: 0.2070 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/17 01:53:23 d2.evaluation.evaluator]: \u001b[0mInference done 74/121. Dataloading: 0.0017 s/iter. Inference: 0.1932 s/iter. Eval: 0.0427 s/iter. Total: 0.2378 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/17 01:53:28 d2.evaluation.evaluator]: \u001b[0mInference done 95/121. Dataloading: 0.0017 s/iter. Inference: 0.1912 s/iter. Eval: 0.0451 s/iter. Total: 0.2382 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/17 01:53:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.343806 (0.218481 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:53:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.169807 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 01:53:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/17 01:53:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.27255212804454054\n",
      "\u001b[32m[12/17 01:53:35 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is0.27255, better than last best score 0.26526 @ iteration 1935.\n",
      "\u001b[32m[12/17 01:54:01 d2.utils.events]: \u001b[0m eta: 2:15:48  iter: 2679  total_loss: 1.397  loss_cls: 0.3263  loss_box_reg: 0.5204  loss_mask: 0.3015  loss_rpn_cls: 0.08187  loss_rpn_loc: 0.1885  time: 1.6212  data_time: 0.3806  lr: 0.00083312  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:54:29 d2.utils.events]: \u001b[0m eta: 2:14:13  iter: 2699  total_loss: 1.29  loss_cls: 0.2937  loss_box_reg: 0.4816  loss_mask: 0.2809  loss_rpn_cls: 0.05622  loss_rpn_loc: 0.1635  time: 1.6196  data_time: 0.6631  lr: 0.00083077  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:55:09 d2.utils.events]: \u001b[0m eta: 2:13:28  iter: 2719  total_loss: 1.43  loss_cls: 0.297  loss_box_reg: 0.4891  loss_mask: 0.3078  loss_rpn_cls: 0.07994  loss_rpn_loc: 0.1982  time: 1.6225  data_time: 1.1727  lr: 0.00082841  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:55:40 d2.utils.events]: \u001b[0m eta: 2:12:47  iter: 2739  total_loss: 1.325  loss_cls: 0.2911  loss_box_reg: 0.4733  loss_mask: 0.297  loss_rpn_cls: 0.05696  loss_rpn_loc: 0.2001  time: 1.6217  data_time: 0.4430  lr: 0.00082604  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:56:08 d2.utils.events]: \u001b[0m eta: 2:13:07  iter: 2759  total_loss: 1.514  loss_cls: 0.3072  loss_box_reg: 0.5121  loss_mask: 0.298  loss_rpn_cls: 0.08614  loss_rpn_loc: 0.1925  time: 1.6203  data_time: 0.4505  lr: 0.00082365  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:56:42 d2.utils.events]: \u001b[0m eta: 2:12:03  iter: 2779  total_loss: 1.505  loss_cls: 0.3656  loss_box_reg: 0.4904  loss_mask: 0.3007  loss_rpn_cls: 0.1148  loss_rpn_loc: 0.2272  time: 1.6208  data_time: 0.8974  lr: 0.00082125  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:57:20 d2.utils.events]: \u001b[0m eta: 2:14:06  iter: 2799  total_loss: 1.476  loss_cls: 0.3233  loss_box_reg: 0.5275  loss_mask: 0.3071  loss_rpn_cls: 0.08379  loss_rpn_loc: 0.202  time: 1.6230  data_time: 0.5064  lr: 0.00081883  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:57:55 d2.utils.events]: \u001b[0m eta: 2:13:53  iter: 2819  total_loss: 1.409  loss_cls: 0.3337  loss_box_reg: 0.4892  loss_mask: 0.289  loss_rpn_cls: 0.07684  loss_rpn_loc: 0.1987  time: 1.6238  data_time: 0.9242  lr: 0.00081641  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:58:28 d2.utils.events]: \u001b[0m eta: 2:13:42  iter: 2839  total_loss: 1.433  loss_cls: 0.3138  loss_box_reg: 0.4923  loss_mask: 0.3047  loss_rpn_cls: 0.0786  loss_rpn_loc: 0.2004  time: 1.6237  data_time: 0.8235  lr: 0.00081397  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:58:58 d2.utils.events]: \u001b[0m eta: 2:12:34  iter: 2859  total_loss: 1.395  loss_cls: 0.307  loss_box_reg: 0.5202  loss_mask: 0.3054  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.1998  time: 1.6231  data_time: 0.7213  lr: 0.00081152  max_mem: 6312M\n",
      "\u001b[32m[12/17 01:59:30 d2.utils.events]: \u001b[0m eta: 2:17:16  iter: 2879  total_loss: 1.36  loss_cls: 0.296  loss_box_reg: 0.4961  loss_mask: 0.2757  loss_rpn_cls: 0.08617  loss_rpn_loc: 0.1968  time: 1.6229  data_time: 0.1819  lr: 0.00080905  max_mem: 6312M\n",
      "\u001b[32m[12/17 02:00:05 d2.utils.events]: \u001b[0m eta: 2:20:07  iter: 2899  total_loss: 1.433  loss_cls: 0.3052  loss_box_reg: 0.5128  loss_mask: 0.2871  loss_rpn_cls: 0.05163  loss_rpn_loc: 0.1978  time: 1.6236  data_time: 0.2741  lr: 0.00080658  max_mem: 6312M\n",
      "\u001b[32m[12/17 02:00:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 02:00:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/17 02:00:12 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/17 02:00:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.73 MiB\n",
      "\u001b[32m[12/17 02:00:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from ../input/sartorius-cell-instance-segmentation-coco/annotations_val.json\n",
      "\u001b[32m[12/17 02:00:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[12/17 02:00:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0018 s/iter. Inference: 0.1266 s/iter. Eval: 0.0326 s/iter. Total: 0.1610 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/17 02:00:19 d2.evaluation.evaluator]: \u001b[0mInference done 33/121. Dataloading: 0.0017 s/iter. Inference: 0.1706 s/iter. Eval: 0.0416 s/iter. Total: 0.2141 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/17 02:00:25 d2.evaluation.evaluator]: \u001b[0mInference done 50/121. Dataloading: 0.0016 s/iter. Inference: 0.2107 s/iter. Eval: 0.0379 s/iter. Total: 0.2503 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/17 02:00:30 d2.evaluation.evaluator]: \u001b[0mInference done 67/121. Dataloading: 0.0016 s/iter. Inference: 0.2277 s/iter. Eval: 0.0358 s/iter. Total: 0.2652 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/17 02:00:35 d2.evaluation.evaluator]: \u001b[0mInference done 84/121. Dataloading: 0.0015 s/iter. Inference: 0.2361 s/iter. Eval: 0.0362 s/iter. Total: 0.2740 s/iter. ETA=0:00:10\n",
      "\u001b[32m[12/17 02:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 101/121. Dataloading: 0.0016 s/iter. Inference: 0.2423 s/iter. Eval: 0.0358 s/iter. Total: 0.2799 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/17 02:00:46 d2.evaluation.evaluator]: \u001b[0mInference done 118/121. Dataloading: 0.0016 s/iter. Inference: 0.2482 s/iter. Eval: 0.0344 s/iter. Total: 0.2844 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/17 02:00:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.175787 (0.285998 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 02:00:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:28 (0.249050 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/17 02:00:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/17 02:00:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2603099771490548\n",
      "\u001b[32m[12/17 02:00:47 d2.engine.hooks]: \u001b[0mNot saving as latest eval score for MaP IoU is 0.26031, not better than best score 0.27255 @ iteration 2661.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize, do not run in server\n",
    "# cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "# predictor = DefaultPredictor(cfg)\n",
    "# dataset_dicts = DatasetCatalog.get('sartorius_val')\n",
    "# outs = []\n",
    "# for d in random.sample(dataset_dicts, 3):    \n",
    "#     im = cv2.imread(d[\"file_name\"])\n",
    "#     outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "#     v = Visualizer(im[:, :, ::-1],\n",
    "#                    metadata = MetadataCatalog.get('sartorius_train'), \n",
    "                    \n",
    "#                    instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "#     )\n",
    "#     out_pred = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "#     visualizer = Visualizer(im[:, :, ::-1], metadata=MetadataCatalog.get('sartorius_train'))\n",
    "#     out_target = visualizer.draw_dataset_dict(d)\n",
    "#     outs.append(out_pred)\n",
    "#     outs.append(out_target)\n",
    "# _,axs = plt.subplots(len(outs)//2,2,figsize=(40,45))\n",
    "# for ax, out in zip(axs.reshape(-1), outs):\n",
    "#     ax.imshow(out.get_image()[:, :, ::-1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5baecada20b3b60ccf8dba9ed8e08a27c8c7ea9ad3aad10d480cd4cf5c4cd7f3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('NMDA_gaoyy': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
